{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdHP7H1IoGdI7y9zb4H6Ej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tantanbei/deep-learning/blob/main/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98TensorFlow%E5%AE%9E%E6%88%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RSdMa-LFAMLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d427173f-57af-4387-cc86-9d9f7806544f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "np.random.seed(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 直接采用np生成等差数列的方法，生成100个点，每个点的取值在-1~1之间\n",
        "\n",
        "x_data = np.linspace(-1, 1, 100)\n",
        "\n",
        "# y = 2x + 1 + 噪声， 其中，噪声的维度与x_data一致\n",
        "y_data = 2 * x_data + 1.0 + np.random.randn(*x_data.shape) * 0.4"
      ],
      "metadata": {
        "id": "ze42oj02CXv6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#画出随机生成数据的散点图\n",
        "plt.scatter(x_data, y_data)\n",
        "\n",
        "#画出我们想要学习到的线性函数 y = 2x + 1\n",
        "plt.plot(x_data, 2 * x_data + 1.0, color = 'red', linewidth = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "KqxbYe-3C1ug",
        "outputId": "a8178869-38c2-426c-cad3-7ebcf1e838c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7aa31ea39f60>]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 构建模型\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None])\n",
        "y = tf.placeholder(tf.float32, [None])\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "w = tf.get_variable('w', [1], initializer=tf.constant_initializer(1.0))\n",
        "b = tf.get_variable('b', [1], initializer=tf.constant_initializer(0.0))\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "\n",
        "y_ = w * x + b\n",
        "\n",
        "#p_y_1 = tf.nn.sigmoid(y_)\n",
        "#print(p_y_1)\n",
        "\n",
        "#y_reshaped = tf.reshape(y, (-1, 1))\n",
        "loss = tf.reduce_mean(tf.square(y - y_))\n",
        "\n",
        "# 定义梯度下降的方法\n",
        "with tf.name_scope('train_op'):\n",
        "    train_op = tf.train.AdamOptimizer(1e-2).minimize(loss)    # 最小化loss，到这里，计算图构建完成\n",
        "\n",
        "\n",
        "#训练\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(1000):\n",
        "      #batch_data = []\n",
        "      #batch_labels = []\n",
        "\n",
        "      #单个样本输入\n",
        "      #for xs, ys in zip(x_data, y_data):\n",
        "      #  w0, b0, loss0, _ = sess.run([w, b, loss,  train_op], feed_dict={x: xs.reshape(1,), y: ys.reshape(1,)})\n",
        "\n",
        "      #全部样本输入\n",
        "      w0, b0, loss0, _ = sess.run([w, b, loss,  train_op], feed_dict={x: x_data, y: y_data})\n",
        "      print('[Train] Step: %d, w: %4.5f, b: %4.5f, loss: %4.5f' % (i, w0[0], b0[0], loss0))\n",
        "\n",
        "    y_p = sess.run(y_, feed_dict={x: [3.21]})\n",
        "    print('预估值: %4.5f, 真实值: %4.5f' % (y_p[0], 3.21 * 2 +1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCbthcUZD0CO",
        "outputId": "2069730b-b040-4695-e63c-0454b86a297b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?,), dtype=float32)\n",
            "Tensor(\"Placeholder_1:0\", shape=(?,), dtype=float32)\n",
            "<tf.Variable 'w:0' shape=(1,) dtype=float32_ref>\n",
            "<tf.Variable 'b:0' shape=(1,) dtype=float32_ref>\n",
            "[Train] Step: 0, w: 1.01000, b: 0.01000, loss: 1.55692\n",
            "[Train] Step: 1, w: 1.02000, b: 0.02000, loss: 1.52948\n",
            "[Train] Step: 2, w: 1.02999, b: 0.02999, loss: 1.50232\n",
            "[Train] Step: 3, w: 1.03998, b: 0.03998, loss: 1.47544\n",
            "[Train] Step: 4, w: 1.04995, b: 0.04996, loss: 1.44885\n",
            "[Train] Step: 5, w: 1.05992, b: 0.05992, loss: 1.42254\n",
            "[Train] Step: 6, w: 1.06988, b: 0.06988, loss: 1.39652\n",
            "[Train] Step: 7, w: 1.07982, b: 0.07982, loss: 1.37080\n",
            "[Train] Step: 8, w: 1.08974, b: 0.08975, loss: 1.34539\n",
            "[Train] Step: 9, w: 1.09965, b: 0.09966, loss: 1.32027\n",
            "[Train] Step: 10, w: 1.10954, b: 0.10956, loss: 1.29547\n",
            "[Train] Step: 11, w: 1.11941, b: 0.11943, loss: 1.27097\n",
            "[Train] Step: 12, w: 1.12925, b: 0.12927, loss: 1.24679\n",
            "[Train] Step: 13, w: 1.13907, b: 0.13910, loss: 1.22292\n",
            "[Train] Step: 14, w: 1.14886, b: 0.14890, loss: 1.19937\n",
            "[Train] Step: 15, w: 1.15862, b: 0.15867, loss: 1.17615\n",
            "[Train] Step: 16, w: 1.16835, b: 0.16841, loss: 1.15324\n",
            "[Train] Step: 17, w: 1.17805, b: 0.17812, loss: 1.13066\n",
            "[Train] Step: 18, w: 1.18772, b: 0.18780, loss: 1.10840\n",
            "[Train] Step: 19, w: 1.19735, b: 0.19744, loss: 1.08648\n",
            "[Train] Step: 20, w: 1.20694, b: 0.20705, loss: 1.06487\n",
            "[Train] Step: 21, w: 1.21650, b: 0.21662, loss: 1.04360\n",
            "[Train] Step: 22, w: 1.22601, b: 0.22615, loss: 1.02266\n",
            "[Train] Step: 23, w: 1.23548, b: 0.23564, loss: 1.00204\n",
            "[Train] Step: 24, w: 1.24491, b: 0.24509, loss: 0.98176\n",
            "[Train] Step: 25, w: 1.25430, b: 0.25450, loss: 0.96180\n",
            "[Train] Step: 26, w: 1.26364, b: 0.26386, loss: 0.94218\n",
            "[Train] Step: 27, w: 1.27293, b: 0.27318, loss: 0.92288\n",
            "[Train] Step: 28, w: 1.28218, b: 0.28245, loss: 0.90390\n",
            "[Train] Step: 29, w: 1.29137, b: 0.29167, loss: 0.88526\n",
            "[Train] Step: 30, w: 1.30052, b: 0.30085, loss: 0.86694\n",
            "[Train] Step: 31, w: 1.30961, b: 0.30997, loss: 0.84894\n",
            "[Train] Step: 32, w: 1.31865, b: 0.31905, loss: 0.83127\n",
            "[Train] Step: 33, w: 1.32763, b: 0.32807, loss: 0.81391\n",
            "[Train] Step: 34, w: 1.33657, b: 0.33704, loss: 0.79687\n",
            "[Train] Step: 35, w: 1.34544, b: 0.34595, loss: 0.78015\n",
            "[Train] Step: 36, w: 1.35426, b: 0.35482, loss: 0.76375\n",
            "[Train] Step: 37, w: 1.36302, b: 0.36362, loss: 0.74765\n",
            "[Train] Step: 38, w: 1.37172, b: 0.37237, loss: 0.73187\n",
            "[Train] Step: 39, w: 1.38037, b: 0.38107, loss: 0.71639\n",
            "[Train] Step: 40, w: 1.38895, b: 0.38970, loss: 0.70122\n",
            "[Train] Step: 41, w: 1.39748, b: 0.39828, loss: 0.68635\n",
            "[Train] Step: 42, w: 1.40594, b: 0.40680, loss: 0.67177\n",
            "[Train] Step: 43, w: 1.41434, b: 0.41526, loss: 0.65749\n",
            "[Train] Step: 44, w: 1.42268, b: 0.42366, loss: 0.64351\n",
            "[Train] Step: 45, w: 1.43095, b: 0.43200, loss: 0.62981\n",
            "[Train] Step: 46, w: 1.43917, b: 0.44028, loss: 0.61640\n",
            "[Train] Step: 47, w: 1.44731, b: 0.44849, loss: 0.60328\n",
            "[Train] Step: 48, w: 1.45540, b: 0.45665, loss: 0.59043\n",
            "[Train] Step: 49, w: 1.46341, b: 0.46474, loss: 0.57786\n",
            "[Train] Step: 50, w: 1.47136, b: 0.47277, loss: 0.56556\n",
            "[Train] Step: 51, w: 1.47925, b: 0.48073, loss: 0.55354\n",
            "[Train] Step: 52, w: 1.48707, b: 0.48864, loss: 0.54177\n",
            "[Train] Step: 53, w: 1.49482, b: 0.49647, loss: 0.53028\n",
            "[Train] Step: 54, w: 1.50251, b: 0.50425, loss: 0.51904\n",
            "[Train] Step: 55, w: 1.51013, b: 0.51196, loss: 0.50805\n",
            "[Train] Step: 56, w: 1.51768, b: 0.51960, loss: 0.49732\n",
            "[Train] Step: 57, w: 1.52516, b: 0.52718, loss: 0.48683\n",
            "[Train] Step: 58, w: 1.53258, b: 0.53469, loss: 0.47659\n",
            "[Train] Step: 59, w: 1.53992, b: 0.54213, loss: 0.46659\n",
            "[Train] Step: 60, w: 1.54720, b: 0.54952, loss: 0.45683\n",
            "[Train] Step: 61, w: 1.55441, b: 0.55683, loss: 0.44730\n",
            "[Train] Step: 62, w: 1.56155, b: 0.56408, loss: 0.43800\n",
            "[Train] Step: 63, w: 1.56862, b: 0.57126, loss: 0.42892\n",
            "[Train] Step: 64, w: 1.57562, b: 0.57837, loss: 0.42007\n",
            "[Train] Step: 65, w: 1.58255, b: 0.58542, loss: 0.41144\n",
            "[Train] Step: 66, w: 1.58942, b: 0.59240, loss: 0.40302\n",
            "[Train] Step: 67, w: 1.59621, b: 0.59931, loss: 0.39481\n",
            "[Train] Step: 68, w: 1.60293, b: 0.60616, loss: 0.38681\n",
            "[Train] Step: 69, w: 1.60959, b: 0.61294, loss: 0.37901\n",
            "[Train] Step: 70, w: 1.61617, b: 0.61965, loss: 0.37142\n",
            "[Train] Step: 71, w: 1.62268, b: 0.62630, loss: 0.36402\n",
            "[Train] Step: 72, w: 1.62913, b: 0.63287, loss: 0.35681\n",
            "[Train] Step: 73, w: 1.63550, b: 0.63938, loss: 0.34979\n",
            "[Train] Step: 74, w: 1.64180, b: 0.64583, loss: 0.34296\n",
            "[Train] Step: 75, w: 1.64804, b: 0.65220, loss: 0.33632\n",
            "[Train] Step: 76, w: 1.65420, b: 0.65851, loss: 0.32985\n",
            "[Train] Step: 77, w: 1.66029, b: 0.66475, loss: 0.32355\n",
            "[Train] Step: 78, w: 1.66632, b: 0.67092, loss: 0.31743\n",
            "[Train] Step: 79, w: 1.67227, b: 0.67703, loss: 0.31147\n",
            "[Train] Step: 80, w: 1.67816, b: 0.68306, loss: 0.30569\n",
            "[Train] Step: 81, w: 1.68398, b: 0.68904, loss: 0.30006\n",
            "[Train] Step: 82, w: 1.68972, b: 0.69494, loss: 0.29459\n",
            "[Train] Step: 83, w: 1.69540, b: 0.70078, loss: 0.28927\n",
            "[Train] Step: 84, w: 1.70101, b: 0.70655, loss: 0.28411\n",
            "[Train] Step: 85, w: 1.70655, b: 0.71225, loss: 0.27910\n",
            "[Train] Step: 86, w: 1.71202, b: 0.71789, loss: 0.27423\n",
            "[Train] Step: 87, w: 1.71742, b: 0.72346, loss: 0.26950\n",
            "[Train] Step: 88, w: 1.72276, b: 0.72896, loss: 0.26492\n",
            "[Train] Step: 89, w: 1.72802, b: 0.73440, loss: 0.26046\n",
            "[Train] Step: 90, w: 1.73322, b: 0.73977, loss: 0.25614\n",
            "[Train] Step: 91, w: 1.73835, b: 0.74508, loss: 0.25195\n",
            "[Train] Step: 92, w: 1.74342, b: 0.75032, loss: 0.24789\n",
            "[Train] Step: 93, w: 1.74841, b: 0.75550, loss: 0.24395\n",
            "[Train] Step: 94, w: 1.75334, b: 0.76061, loss: 0.24013\n",
            "[Train] Step: 95, w: 1.75820, b: 0.76565, loss: 0.23643\n",
            "[Train] Step: 96, w: 1.76300, b: 0.77064, loss: 0.23285\n",
            "[Train] Step: 97, w: 1.76773, b: 0.77555, loss: 0.22938\n",
            "[Train] Step: 98, w: 1.77240, b: 0.78041, loss: 0.22601\n",
            "[Train] Step: 99, w: 1.77700, b: 0.78519, loss: 0.22276\n",
            "预估值: 6.48935, 真实值: 7.42000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 构建模型\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(\"float\", name=\"x\")\n",
        "y = tf.placeholder(\"float\", name=\"y\")\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "w = tf.Variable(0.0, name='w0')\n",
        "b = tf.Variable(0.0, name='b0')\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "\n",
        "y_ = w * x + b\n",
        "\n",
        "#p_y_1 = tf.nn.sigmoid(y_)\n",
        "#print(p_y_1)\n",
        "\n",
        "#y_reshaped = tf.reshape(y, (-1, 1))\n",
        "loss = tf.reduce_mean(tf.square(y - y_))\n",
        "\n",
        "# 定义梯度下降的方法\n",
        "with tf.name_scope('train_op'):\n",
        "    train_op = tf.train.AdamOptimizer(1e-2).minimize(loss)    # 最小化loss，到这里，计算图构建完成\n",
        "\n",
        "\n",
        "#训练\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(10):\n",
        "      #batch_data = []\n",
        "      #batch_labels = []\n",
        "\n",
        "      #单个样本输入\n",
        "      for xs, ys in zip(x_data, y_data):\n",
        "      #batch_data = tf.cast(tf.convert_to_tensor(x_data[i]), tf.float32)\n",
        "      #batch_labels = tf.cast(tf.convert_to_tensor(y_data[i]), tf.float32)\n",
        "      #print(batch_data.shape)\n",
        "      #print(batch_labels.shape)\n",
        "        #batch_data.append(xs)\n",
        "        #batch_data.append(ys)\n",
        "        #print('[Train] Step: %d start' % (i))\n",
        "        #print(xs, ys)\n",
        "        w0, b0, loss0, _ = sess.run([w, b, loss,  train_op], feed_dict={x: xs, y: ys})\n",
        "\n",
        "      #所有样本输入\n",
        "      #w0, b0, loss0, _ = sess.run([w, b, loss,  train_op], feed_dict={x: x_data, y: y_data})\n",
        "\n",
        "      print('[Train] Step: %d, w: %4.5f, b: %4.5f, loss: %4.5f' % (i, w0, b0, loss0))\n",
        "\n",
        "    y_p = sess.run(y_, feed_dict={x: 3.21})\n",
        "    print('预估值: %4.5f, 真实值: %4.5f' % (y_p, 3.21 * 2 +1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rBQtqkIHRo-",
        "outputId": "33bee1c7-d6e9-400a-e66a-2baaf46cff1f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"x:0\", dtype=float32)\n",
            "Tensor(\"y:0\", dtype=float32)\n",
            "<tf.Variable 'w0:0' shape=() dtype=float32_ref>\n",
            "<tf.Variable 'b0:0' shape=() dtype=float32_ref>\n",
            "[Train] Step: 0, w: 0.01000, b: 0.01000, loss: 2.58072\n",
            "[Train] Step: 1, w: 0.02000, b: 0.02000, loss: 2.54648\n",
            "[Train] Step: 2, w: 0.02999, b: 0.02999, loss: 2.51252\n",
            "[Train] Step: 3, w: 0.03999, b: 0.03998, loss: 2.47884\n",
            "[Train] Step: 4, w: 0.04998, b: 0.04996, loss: 2.44544\n",
            "[Train] Step: 5, w: 0.05996, b: 0.05992, loss: 2.41233\n",
            "[Train] Step: 6, w: 0.06994, b: 0.06988, loss: 2.37952\n",
            "[Train] Step: 7, w: 0.07991, b: 0.07982, loss: 2.34700\n",
            "[Train] Step: 8, w: 0.08988, b: 0.08975, loss: 2.31478\n",
            "[Train] Step: 9, w: 0.09983, b: 0.09966, loss: 2.28286\n",
            "[Train] Step: 10, w: 0.10978, b: 0.10956, loss: 2.25126\n",
            "[Train] Step: 11, w: 0.11972, b: 0.11943, loss: 2.21996\n",
            "[Train] Step: 12, w: 0.12964, b: 0.12927, loss: 2.18898\n",
            "[Train] Step: 13, w: 0.13955, b: 0.13910, loss: 2.15832\n",
            "[Train] Step: 14, w: 0.14946, b: 0.14890, loss: 2.12797\n",
            "[Train] Step: 15, w: 0.15934, b: 0.15867, loss: 2.09795\n",
            "[Train] Step: 16, w: 0.16922, b: 0.16841, loss: 2.06825\n",
            "[Train] Step: 17, w: 0.17908, b: 0.17812, loss: 2.03888\n",
            "[Train] Step: 18, w: 0.18892, b: 0.18780, loss: 2.00983\n",
            "[Train] Step: 19, w: 0.19875, b: 0.19744, loss: 1.98112\n",
            "[Train] Step: 20, w: 0.20856, b: 0.20705, loss: 1.95273\n",
            "[Train] Step: 21, w: 0.21835, b: 0.21662, loss: 1.92468\n",
            "[Train] Step: 22, w: 0.22813, b: 0.22615, loss: 1.89696\n",
            "[Train] Step: 23, w: 0.23788, b: 0.23564, loss: 1.86957\n",
            "[Train] Step: 24, w: 0.24762, b: 0.24509, loss: 1.84252\n",
            "[Train] Step: 25, w: 0.25733, b: 0.25450, loss: 1.81579\n",
            "[Train] Step: 26, w: 0.26703, b: 0.26386, loss: 1.78941\n",
            "[Train] Step: 27, w: 0.27671, b: 0.27318, loss: 1.76335\n",
            "[Train] Step: 28, w: 0.28636, b: 0.28245, loss: 1.73763\n",
            "[Train] Step: 29, w: 0.29599, b: 0.29167, loss: 1.71224\n",
            "[Train] Step: 30, w: 0.30560, b: 0.30085, loss: 1.68719\n",
            "[Train] Step: 31, w: 0.31519, b: 0.30997, loss: 1.66246\n",
            "[Train] Step: 32, w: 0.32475, b: 0.31905, loss: 1.63807\n",
            "[Train] Step: 33, w: 0.33429, b: 0.32807, loss: 1.61400\n",
            "[Train] Step: 34, w: 0.34381, b: 0.33704, loss: 1.59026\n",
            "[Train] Step: 35, w: 0.35330, b: 0.34595, loss: 1.56684\n",
            "[Train] Step: 36, w: 0.36276, b: 0.35482, loss: 1.54375\n",
            "[Train] Step: 37, w: 0.37221, b: 0.36362, loss: 1.52098\n",
            "[Train] Step: 38, w: 0.38162, b: 0.37237, loss: 1.49854\n",
            "[Train] Step: 39, w: 0.39101, b: 0.38107, loss: 1.47640\n",
            "[Train] Step: 40, w: 0.40038, b: 0.38970, loss: 1.45459\n",
            "[Train] Step: 41, w: 0.40972, b: 0.39828, loss: 1.43309\n",
            "[Train] Step: 42, w: 0.41903, b: 0.40680, loss: 1.41190\n",
            "[Train] Step: 43, w: 0.42832, b: 0.41526, loss: 1.39102\n",
            "[Train] Step: 44, w: 0.43757, b: 0.42366, loss: 1.37045\n",
            "[Train] Step: 45, w: 0.44681, b: 0.43200, loss: 1.35018\n",
            "[Train] Step: 46, w: 0.45601, b: 0.44028, loss: 1.33021\n",
            "[Train] Step: 47, w: 0.46519, b: 0.44849, loss: 1.31054\n",
            "[Train] Step: 48, w: 0.47434, b: 0.45665, loss: 1.29117\n",
            "[Train] Step: 49, w: 0.48346, b: 0.46474, loss: 1.27209\n",
            "[Train] Step: 50, w: 0.49255, b: 0.47277, loss: 1.25330\n",
            "[Train] Step: 51, w: 0.50162, b: 0.48073, loss: 1.23479\n",
            "[Train] Step: 52, w: 0.51066, b: 0.48864, loss: 1.21657\n",
            "[Train] Step: 53, w: 0.51967, b: 0.49647, loss: 1.19864\n",
            "[Train] Step: 54, w: 0.52865, b: 0.50425, loss: 1.18098\n",
            "[Train] Step: 55, w: 0.53760, b: 0.51195, loss: 1.16359\n",
            "[Train] Step: 56, w: 0.54652, b: 0.51960, loss: 1.14648\n",
            "[Train] Step: 57, w: 0.55542, b: 0.52718, loss: 1.12964\n",
            "[Train] Step: 58, w: 0.56428, b: 0.53469, loss: 1.11307\n",
            "[Train] Step: 59, w: 0.57312, b: 0.54213, loss: 1.09675\n",
            "[Train] Step: 60, w: 0.58192, b: 0.54952, loss: 1.08070\n",
            "[Train] Step: 61, w: 0.59070, b: 0.55683, loss: 1.06490\n",
            "[Train] Step: 62, w: 0.59945, b: 0.56408, loss: 1.04936\n",
            "[Train] Step: 63, w: 0.60817, b: 0.57126, loss: 1.03407\n",
            "[Train] Step: 64, w: 0.61686, b: 0.57837, loss: 1.01902\n",
            "[Train] Step: 65, w: 0.62552, b: 0.58542, loss: 1.00422\n",
            "[Train] Step: 66, w: 0.63414, b: 0.59240, loss: 0.98966\n",
            "[Train] Step: 67, w: 0.64274, b: 0.59931, loss: 0.97533\n",
            "[Train] Step: 68, w: 0.65131, b: 0.60616, loss: 0.96125\n",
            "[Train] Step: 69, w: 0.65985, b: 0.61294, loss: 0.94739\n",
            "[Train] Step: 70, w: 0.66836, b: 0.61965, loss: 0.93376\n",
            "[Train] Step: 71, w: 0.67684, b: 0.62630, loss: 0.92035\n",
            "[Train] Step: 72, w: 0.68529, b: 0.63287, loss: 0.90717\n",
            "[Train] Step: 73, w: 0.69371, b: 0.63938, loss: 0.89421\n",
            "[Train] Step: 74, w: 0.70210, b: 0.64583, loss: 0.88146\n",
            "[Train] Step: 75, w: 0.71046, b: 0.65220, loss: 0.86892\n",
            "[Train] Step: 76, w: 0.71879, b: 0.65851, loss: 0.85659\n",
            "[Train] Step: 77, w: 0.72709, b: 0.66475, loss: 0.84447\n",
            "[Train] Step: 78, w: 0.73535, b: 0.67092, loss: 0.83256\n",
            "[Train] Step: 79, w: 0.74359, b: 0.67703, loss: 0.82084\n",
            "[Train] Step: 80, w: 0.75180, b: 0.68306, loss: 0.80932\n",
            "[Train] Step: 81, w: 0.75997, b: 0.68904, loss: 0.79799\n",
            "[Train] Step: 82, w: 0.76812, b: 0.69494, loss: 0.78686\n",
            "[Train] Step: 83, w: 0.77623, b: 0.70078, loss: 0.77592\n",
            "[Train] Step: 84, w: 0.78432, b: 0.70655, loss: 0.76516\n",
            "[Train] Step: 85, w: 0.79237, b: 0.71225, loss: 0.75458\n",
            "[Train] Step: 86, w: 0.80039, b: 0.71789, loss: 0.74418\n",
            "[Train] Step: 87, w: 0.80838, b: 0.72346, loss: 0.73396\n",
            "[Train] Step: 88, w: 0.81634, b: 0.72896, loss: 0.72391\n",
            "[Train] Step: 89, w: 0.82427, b: 0.73440, loss: 0.71404\n",
            "[Train] Step: 90, w: 0.83217, b: 0.73977, loss: 0.70433\n",
            "[Train] Step: 91, w: 0.84003, b: 0.74508, loss: 0.69479\n",
            "[Train] Step: 92, w: 0.84787, b: 0.75032, loss: 0.68541\n",
            "[Train] Step: 93, w: 0.85568, b: 0.75550, loss: 0.67619\n",
            "[Train] Step: 94, w: 0.86345, b: 0.76061, loss: 0.66713\n",
            "[Train] Step: 95, w: 0.87119, b: 0.76565, loss: 0.65823\n",
            "[Train] Step: 96, w: 0.87890, b: 0.77064, loss: 0.64947\n",
            "[Train] Step: 97, w: 0.88658, b: 0.77555, loss: 0.64087\n",
            "[Train] Step: 98, w: 0.89423, b: 0.78041, loss: 0.63242\n",
            "[Train] Step: 99, w: 0.90185, b: 0.78519, loss: 0.62411\n",
            "[Train] Step: 100, w: 0.90944, b: 0.78992, loss: 0.61594\n",
            "[Train] Step: 101, w: 0.91699, b: 0.79458, loss: 0.60791\n",
            "[Train] Step: 102, w: 0.92451, b: 0.79918, loss: 0.60002\n",
            "[Train] Step: 103, w: 0.93201, b: 0.80372, loss: 0.59227\n",
            "[Train] Step: 104, w: 0.93947, b: 0.80819, loss: 0.58465\n",
            "[Train] Step: 105, w: 0.94690, b: 0.81260, loss: 0.57715\n",
            "[Train] Step: 106, w: 0.95429, b: 0.81696, loss: 0.56979\n",
            "[Train] Step: 107, w: 0.96166, b: 0.82124, loss: 0.56255\n",
            "[Train] Step: 108, w: 0.96899, b: 0.82547, loss: 0.55544\n",
            "[Train] Step: 109, w: 0.97630, b: 0.82964, loss: 0.54845\n",
            "[Train] Step: 110, w: 0.98357, b: 0.83375, loss: 0.54158\n",
            "[Train] Step: 111, w: 0.99081, b: 0.83780, loss: 0.53482\n",
            "[Train] Step: 112, w: 0.99802, b: 0.84178, loss: 0.52818\n",
            "[Train] Step: 113, w: 1.00520, b: 0.84571, loss: 0.52166\n",
            "[Train] Step: 114, w: 1.01234, b: 0.84958, loss: 0.51524\n",
            "[Train] Step: 115, w: 1.01946, b: 0.85339, loss: 0.50894\n",
            "[Train] Step: 116, w: 1.02654, b: 0.85715, loss: 0.50274\n",
            "[Train] Step: 117, w: 1.03359, b: 0.86084, loss: 0.49664\n",
            "[Train] Step: 118, w: 1.04061, b: 0.86448, loss: 0.49065\n",
            "[Train] Step: 119, w: 1.04760, b: 0.86807, loss: 0.48477\n",
            "[Train] Step: 120, w: 1.05455, b: 0.87159, loss: 0.47898\n",
            "[Train] Step: 121, w: 1.06148, b: 0.87506, loss: 0.47329\n",
            "[Train] Step: 122, w: 1.06837, b: 0.87848, loss: 0.46769\n",
            "[Train] Step: 123, w: 1.07523, b: 0.88184, loss: 0.46219\n",
            "[Train] Step: 124, w: 1.08206, b: 0.88515, loss: 0.45678\n",
            "[Train] Step: 125, w: 1.08886, b: 0.88840, loss: 0.45147\n",
            "[Train] Step: 126, w: 1.09562, b: 0.89160, loss: 0.44624\n",
            "[Train] Step: 127, w: 1.10236, b: 0.89474, loss: 0.44110\n",
            "[Train] Step: 128, w: 1.10906, b: 0.89784, loss: 0.43605\n",
            "[Train] Step: 129, w: 1.11573, b: 0.90088, loss: 0.43108\n",
            "[Train] Step: 130, w: 1.12237, b: 0.90387, loss: 0.42619\n",
            "[Train] Step: 131, w: 1.12898, b: 0.90681, loss: 0.42139\n",
            "[Train] Step: 132, w: 1.13555, b: 0.90970, loss: 0.41666\n",
            "[Train] Step: 133, w: 1.14210, b: 0.91254, loss: 0.41202\n",
            "[Train] Step: 134, w: 1.14861, b: 0.91533, loss: 0.40745\n",
            "[Train] Step: 135, w: 1.15509, b: 0.91807, loss: 0.40295\n",
            "[Train] Step: 136, w: 1.16154, b: 0.92076, loss: 0.39853\n",
            "[Train] Step: 137, w: 1.16796, b: 0.92340, loss: 0.39419\n",
            "[Train] Step: 138, w: 1.17434, b: 0.92600, loss: 0.38991\n",
            "[Train] Step: 139, w: 1.18070, b: 0.92855, loss: 0.38571\n",
            "[Train] Step: 140, w: 1.18702, b: 0.93105, loss: 0.38157\n",
            "[Train] Step: 141, w: 1.19331, b: 0.93351, loss: 0.37751\n",
            "[Train] Step: 142, w: 1.19957, b: 0.93592, loss: 0.37351\n",
            "[Train] Step: 143, w: 1.20580, b: 0.93829, loss: 0.36957\n",
            "[Train] Step: 144, w: 1.21199, b: 0.94061, loss: 0.36570\n",
            "[Train] Step: 145, w: 1.21816, b: 0.94289, loss: 0.36189\n",
            "[Train] Step: 146, w: 1.22429, b: 0.94512, loss: 0.35815\n",
            "[Train] Step: 147, w: 1.23039, b: 0.94732, loss: 0.35446\n",
            "[Train] Step: 148, w: 1.23647, b: 0.94947, loss: 0.35084\n",
            "[Train] Step: 149, w: 1.24250, b: 0.95158, loss: 0.34727\n",
            "[Train] Step: 150, w: 1.24851, b: 0.95365, loss: 0.34376\n",
            "[Train] Step: 151, w: 1.25449, b: 0.95567, loss: 0.34031\n",
            "[Train] Step: 152, w: 1.26043, b: 0.95766, loss: 0.33692\n",
            "[Train] Step: 153, w: 1.26635, b: 0.95961, loss: 0.33357\n",
            "[Train] Step: 154, w: 1.27223, b: 0.96152, loss: 0.33029\n",
            "[Train] Step: 155, w: 1.27808, b: 0.96339, loss: 0.32705\n",
            "[Train] Step: 156, w: 1.28390, b: 0.96522, loss: 0.32387\n",
            "[Train] Step: 157, w: 1.28969, b: 0.96702, loss: 0.32074\n",
            "[Train] Step: 158, w: 1.29544, b: 0.96877, loss: 0.31766\n",
            "[Train] Step: 159, w: 1.30117, b: 0.97050, loss: 0.31462\n",
            "[Train] Step: 160, w: 1.30686, b: 0.97218, loss: 0.31164\n",
            "[Train] Step: 161, w: 1.31252, b: 0.97383, loss: 0.30870\n",
            "[Train] Step: 162, w: 1.31816, b: 0.97545, loss: 0.30581\n",
            "[Train] Step: 163, w: 1.32376, b: 0.97703, loss: 0.30297\n",
            "[Train] Step: 164, w: 1.32933, b: 0.97858, loss: 0.30017\n",
            "[Train] Step: 165, w: 1.33487, b: 0.98010, loss: 0.29742\n",
            "[Train] Step: 166, w: 1.34037, b: 0.98158, loss: 0.29471\n",
            "[Train] Step: 167, w: 1.34585, b: 0.98303, loss: 0.29204\n",
            "[Train] Step: 168, w: 1.35130, b: 0.98445, loss: 0.28942\n",
            "[Train] Step: 169, w: 1.35671, b: 0.98583, loss: 0.28684\n",
            "[Train] Step: 170, w: 1.36210, b: 0.98719, loss: 0.28429\n",
            "[Train] Step: 171, w: 1.36745, b: 0.98852, loss: 0.28179\n",
            "[Train] Step: 172, w: 1.37277, b: 0.98981, loss: 0.27933\n",
            "[Train] Step: 173, w: 1.37807, b: 0.99108, loss: 0.27691\n",
            "[Train] Step: 174, w: 1.38333, b: 0.99232, loss: 0.27453\n",
            "[Train] Step: 175, w: 1.38856, b: 0.99353, loss: 0.27218\n",
            "[Train] Step: 176, w: 1.39376, b: 0.99471, loss: 0.26987\n",
            "[Train] Step: 177, w: 1.39893, b: 0.99587, loss: 0.26760\n",
            "[Train] Step: 178, w: 1.40407, b: 0.99700, loss: 0.26536\n",
            "[Train] Step: 179, w: 1.40918, b: 0.99810, loss: 0.26316\n",
            "[Train] Step: 180, w: 1.41426, b: 0.99918, loss: 0.26099\n",
            "[Train] Step: 181, w: 1.41930, b: 1.00023, loss: 0.25886\n",
            "[Train] Step: 182, w: 1.42432, b: 1.00126, loss: 0.25676\n",
            "[Train] Step: 183, w: 1.42931, b: 1.00226, loss: 0.25470\n",
            "[Train] Step: 184, w: 1.43427, b: 1.00324, loss: 0.25266\n",
            "[Train] Step: 185, w: 1.43919, b: 1.00419, loss: 0.25066\n",
            "[Train] Step: 186, w: 1.44409, b: 1.00512, loss: 0.24870\n",
            "[Train] Step: 187, w: 1.44896, b: 1.00603, loss: 0.24676\n",
            "[Train] Step: 188, w: 1.45380, b: 1.00692, loss: 0.24485\n",
            "[Train] Step: 189, w: 1.45861, b: 1.00778, loss: 0.24298\n",
            "[Train] Step: 190, w: 1.46338, b: 1.00862, loss: 0.24113\n",
            "[Train] Step: 191, w: 1.46813, b: 1.00945, loss: 0.23931\n",
            "[Train] Step: 192, w: 1.47285, b: 1.01025, loss: 0.23753\n",
            "[Train] Step: 193, w: 1.47754, b: 1.01103, loss: 0.23577\n",
            "[Train] Step: 194, w: 1.48220, b: 1.01179, loss: 0.23404\n",
            "[Train] Step: 195, w: 1.48683, b: 1.01253, loss: 0.23233\n",
            "[Train] Step: 196, w: 1.49143, b: 1.01326, loss: 0.23066\n",
            "[Train] Step: 197, w: 1.49600, b: 1.01396, loss: 0.22901\n",
            "[Train] Step: 198, w: 1.50054, b: 1.01465, loss: 0.22738\n",
            "[Train] Step: 199, w: 1.50506, b: 1.01531, loss: 0.22579\n",
            "[Train] Step: 200, w: 1.50954, b: 1.01597, loss: 0.22422\n",
            "[Train] Step: 201, w: 1.51399, b: 1.01660, loss: 0.22267\n",
            "[Train] Step: 202, w: 1.51842, b: 1.01722, loss: 0.22115\n",
            "[Train] Step: 203, w: 1.52282, b: 1.01782, loss: 0.21965\n",
            "[Train] Step: 204, w: 1.52718, b: 1.01840, loss: 0.21818\n",
            "[Train] Step: 205, w: 1.53152, b: 1.01897, loss: 0.21673\n",
            "[Train] Step: 206, w: 1.53583, b: 1.01952, loss: 0.21531\n",
            "[Train] Step: 207, w: 1.54012, b: 1.02006, loss: 0.21390\n",
            "[Train] Step: 208, w: 1.54437, b: 1.02059, loss: 0.21253\n",
            "[Train] Step: 209, w: 1.54859, b: 1.02110, loss: 0.21117\n",
            "[Train] Step: 210, w: 1.55279, b: 1.02159, loss: 0.20983\n",
            "[Train] Step: 211, w: 1.55696, b: 1.02207, loss: 0.20852\n",
            "[Train] Step: 212, w: 1.56110, b: 1.02254, loss: 0.20723\n",
            "[Train] Step: 213, w: 1.56521, b: 1.02300, loss: 0.20596\n",
            "[Train] Step: 214, w: 1.56929, b: 1.02344, loss: 0.20471\n",
            "[Train] Step: 215, w: 1.57335, b: 1.02387, loss: 0.20348\n",
            "[Train] Step: 216, w: 1.57738, b: 1.02429, loss: 0.20228\n",
            "[Train] Step: 217, w: 1.58138, b: 1.02469, loss: 0.20109\n",
            "[Train] Step: 218, w: 1.58535, b: 1.02509, loss: 0.19992\n",
            "[Train] Step: 219, w: 1.58929, b: 1.02547, loss: 0.19877\n",
            "[Train] Step: 220, w: 1.59321, b: 1.02584, loss: 0.19764\n",
            "[Train] Step: 221, w: 1.59710, b: 1.02620, loss: 0.19653\n",
            "[Train] Step: 222, w: 1.60096, b: 1.02655, loss: 0.19544\n",
            "[Train] Step: 223, w: 1.60480, b: 1.02689, loss: 0.19436\n",
            "[Train] Step: 224, w: 1.60860, b: 1.02722, loss: 0.19331\n",
            "[Train] Step: 225, w: 1.61239, b: 1.02754, loss: 0.19227\n",
            "[Train] Step: 226, w: 1.61614, b: 1.02785, loss: 0.19125\n",
            "[Train] Step: 227, w: 1.61987, b: 1.02815, loss: 0.19024\n",
            "[Train] Step: 228, w: 1.62357, b: 1.02845, loss: 0.18925\n",
            "[Train] Step: 229, w: 1.62724, b: 1.02873, loss: 0.18828\n",
            "[Train] Step: 230, w: 1.63088, b: 1.02900, loss: 0.18733\n",
            "[Train] Step: 231, w: 1.63450, b: 1.02927, loss: 0.18639\n",
            "[Train] Step: 232, w: 1.63810, b: 1.02953, loss: 0.18547\n",
            "[Train] Step: 233, w: 1.64166, b: 1.02978, loss: 0.18457\n",
            "[Train] Step: 234, w: 1.64521, b: 1.03002, loss: 0.18368\n",
            "[Train] Step: 235, w: 1.64872, b: 1.03026, loss: 0.18280\n",
            "[Train] Step: 236, w: 1.65221, b: 1.03048, loss: 0.18194\n",
            "[Train] Step: 237, w: 1.65567, b: 1.03070, loss: 0.18110\n",
            "[Train] Step: 238, w: 1.65911, b: 1.03092, loss: 0.18027\n",
            "[Train] Step: 239, w: 1.66252, b: 1.03112, loss: 0.17945\n",
            "[Train] Step: 240, w: 1.66590, b: 1.03132, loss: 0.17865\n",
            "[Train] Step: 241, w: 1.66926, b: 1.03152, loss: 0.17786\n",
            "[Train] Step: 242, w: 1.67260, b: 1.03170, loss: 0.17709\n",
            "[Train] Step: 243, w: 1.67591, b: 1.03188, loss: 0.17633\n",
            "[Train] Step: 244, w: 1.67919, b: 1.03206, loss: 0.17558\n",
            "[Train] Step: 245, w: 1.68245, b: 1.03223, loss: 0.17485\n",
            "[Train] Step: 246, w: 1.68568, b: 1.03239, loss: 0.17413\n",
            "[Train] Step: 247, w: 1.68889, b: 1.03255, loss: 0.17342\n",
            "[Train] Step: 248, w: 1.69207, b: 1.03270, loss: 0.17273\n",
            "[Train] Step: 249, w: 1.69523, b: 1.03285, loss: 0.17204\n",
            "[Train] Step: 250, w: 1.69837, b: 1.03300, loss: 0.17137\n",
            "[Train] Step: 251, w: 1.70148, b: 1.03313, loss: 0.17071\n",
            "[Train] Step: 252, w: 1.70456, b: 1.03327, loss: 0.17007\n",
            "[Train] Step: 253, w: 1.70762, b: 1.03340, loss: 0.16943\n",
            "[Train] Step: 254, w: 1.71066, b: 1.03352, loss: 0.16881\n",
            "[Train] Step: 255, w: 1.71367, b: 1.03364, loss: 0.16820\n",
            "[Train] Step: 256, w: 1.71666, b: 1.03376, loss: 0.16759\n",
            "[Train] Step: 257, w: 1.71962, b: 1.03387, loss: 0.16700\n",
            "[Train] Step: 258, w: 1.72257, b: 1.03398, loss: 0.16642\n",
            "[Train] Step: 259, w: 1.72548, b: 1.03408, loss: 0.16585\n",
            "[Train] Step: 260, w: 1.72838, b: 1.03418, loss: 0.16530\n",
            "[Train] Step: 261, w: 1.73125, b: 1.03428, loss: 0.16475\n",
            "[Train] Step: 262, w: 1.73409, b: 1.03438, loss: 0.16421\n",
            "[Train] Step: 263, w: 1.73692, b: 1.03447, loss: 0.16368\n",
            "[Train] Step: 264, w: 1.73972, b: 1.03455, loss: 0.16316\n",
            "[Train] Step: 265, w: 1.74250, b: 1.03464, loss: 0.16265\n",
            "[Train] Step: 266, w: 1.74525, b: 1.03472, loss: 0.16215\n",
            "[Train] Step: 267, w: 1.74798, b: 1.03480, loss: 0.16166\n",
            "[Train] Step: 268, w: 1.75069, b: 1.03487, loss: 0.16118\n",
            "[Train] Step: 269, w: 1.75338, b: 1.03494, loss: 0.16071\n",
            "[Train] Step: 270, w: 1.75604, b: 1.03501, loss: 0.16025\n",
            "[Train] Step: 271, w: 1.75868, b: 1.03508, loss: 0.15979\n",
            "[Train] Step: 272, w: 1.76130, b: 1.03515, loss: 0.15935\n",
            "[Train] Step: 273, w: 1.76390, b: 1.03521, loss: 0.15891\n",
            "[Train] Step: 274, w: 1.76648, b: 1.03527, loss: 0.15848\n",
            "[Train] Step: 275, w: 1.76903, b: 1.03533, loss: 0.15806\n",
            "[Train] Step: 276, w: 1.77156, b: 1.03538, loss: 0.15765\n",
            "[Train] Step: 277, w: 1.77407, b: 1.03543, loss: 0.15724\n",
            "[Train] Step: 278, w: 1.77656, b: 1.03549, loss: 0.15685\n",
            "[Train] Step: 279, w: 1.77903, b: 1.03554, loss: 0.15646\n",
            "[Train] Step: 280, w: 1.78148, b: 1.03558, loss: 0.15608\n",
            "[Train] Step: 281, w: 1.78390, b: 1.03563, loss: 0.15570\n",
            "[Train] Step: 282, w: 1.78631, b: 1.03567, loss: 0.15533\n",
            "[Train] Step: 283, w: 1.78869, b: 1.03571, loss: 0.15497\n",
            "[Train] Step: 284, w: 1.79105, b: 1.03575, loss: 0.15462\n",
            "[Train] Step: 285, w: 1.79339, b: 1.03579, loss: 0.15427\n",
            "[Train] Step: 286, w: 1.79571, b: 1.03583, loss: 0.15394\n",
            "[Train] Step: 287, w: 1.79801, b: 1.03587, loss: 0.15360\n",
            "[Train] Step: 288, w: 1.80029, b: 1.03590, loss: 0.15328\n",
            "[Train] Step: 289, w: 1.80255, b: 1.03593, loss: 0.15296\n",
            "[Train] Step: 290, w: 1.80479, b: 1.03596, loss: 0.15264\n",
            "[Train] Step: 291, w: 1.80701, b: 1.03600, loss: 0.15234\n",
            "[Train] Step: 292, w: 1.80921, b: 1.03602, loss: 0.15204\n",
            "[Train] Step: 293, w: 1.81139, b: 1.03605, loss: 0.15174\n",
            "[Train] Step: 294, w: 1.81355, b: 1.03608, loss: 0.15145\n",
            "[Train] Step: 295, w: 1.81569, b: 1.03610, loss: 0.15117\n",
            "[Train] Step: 296, w: 1.81782, b: 1.03613, loss: 0.15089\n",
            "[Train] Step: 297, w: 1.81992, b: 1.03615, loss: 0.15062\n",
            "[Train] Step: 298, w: 1.82200, b: 1.03617, loss: 0.15035\n",
            "[Train] Step: 299, w: 1.82406, b: 1.03620, loss: 0.15009\n",
            "[Train] Step: 300, w: 1.82611, b: 1.03622, loss: 0.14983\n",
            "[Train] Step: 301, w: 1.82814, b: 1.03624, loss: 0.14958\n",
            "[Train] Step: 302, w: 1.83014, b: 1.03626, loss: 0.14934\n",
            "[Train] Step: 303, w: 1.83213, b: 1.03627, loss: 0.14910\n",
            "[Train] Step: 304, w: 1.83410, b: 1.03629, loss: 0.14886\n",
            "[Train] Step: 305, w: 1.83605, b: 1.03631, loss: 0.14863\n",
            "[Train] Step: 306, w: 1.83799, b: 1.03632, loss: 0.14841\n",
            "[Train] Step: 307, w: 1.83990, b: 1.03634, loss: 0.14818\n",
            "[Train] Step: 308, w: 1.84180, b: 1.03635, loss: 0.14797\n",
            "[Train] Step: 309, w: 1.84368, b: 1.03637, loss: 0.14775\n",
            "[Train] Step: 310, w: 1.84554, b: 1.03638, loss: 0.14755\n",
            "[Train] Step: 311, w: 1.84739, b: 1.03639, loss: 0.14734\n",
            "[Train] Step: 312, w: 1.84922, b: 1.03640, loss: 0.14714\n",
            "[Train] Step: 313, w: 1.85102, b: 1.03641, loss: 0.14695\n",
            "[Train] Step: 314, w: 1.85282, b: 1.03643, loss: 0.14676\n",
            "[Train] Step: 315, w: 1.85459, b: 1.03644, loss: 0.14657\n",
            "[Train] Step: 316, w: 1.85635, b: 1.03645, loss: 0.14639\n",
            "[Train] Step: 317, w: 1.85809, b: 1.03645, loss: 0.14621\n",
            "[Train] Step: 318, w: 1.85981, b: 1.03646, loss: 0.14603\n",
            "[Train] Step: 319, w: 1.86152, b: 1.03647, loss: 0.14586\n",
            "[Train] Step: 320, w: 1.86321, b: 1.03648, loss: 0.14569\n",
            "[Train] Step: 321, w: 1.86489, b: 1.03649, loss: 0.14553\n",
            "[Train] Step: 322, w: 1.86654, b: 1.03650, loss: 0.14537\n",
            "[Train] Step: 323, w: 1.86819, b: 1.03650, loss: 0.14521\n",
            "[Train] Step: 324, w: 1.86981, b: 1.03651, loss: 0.14506\n",
            "[Train] Step: 325, w: 1.87142, b: 1.03652, loss: 0.14491\n",
            "[Train] Step: 326, w: 1.87301, b: 1.03652, loss: 0.14476\n",
            "[Train] Step: 327, w: 1.87459, b: 1.03653, loss: 0.14462\n",
            "[Train] Step: 328, w: 1.87615, b: 1.03653, loss: 0.14447\n",
            "[Train] Step: 329, w: 1.87770, b: 1.03654, loss: 0.14434\n",
            "[Train] Step: 330, w: 1.87923, b: 1.03654, loss: 0.14420\n",
            "[Train] Step: 331, w: 1.88074, b: 1.03655, loss: 0.14407\n",
            "[Train] Step: 332, w: 1.88225, b: 1.03655, loss: 0.14394\n",
            "[Train] Step: 333, w: 1.88373, b: 1.03656, loss: 0.14381\n",
            "[Train] Step: 334, w: 1.88520, b: 1.03656, loss: 0.14369\n",
            "[Train] Step: 335, w: 1.88666, b: 1.03656, loss: 0.14357\n",
            "[Train] Step: 336, w: 1.88810, b: 1.03657, loss: 0.14345\n",
            "[Train] Step: 337, w: 1.88952, b: 1.03657, loss: 0.14334\n",
            "[Train] Step: 338, w: 1.89093, b: 1.03657, loss: 0.14322\n",
            "[Train] Step: 339, w: 1.89233, b: 1.03658, loss: 0.14311\n",
            "[Train] Step: 340, w: 1.89371, b: 1.03658, loss: 0.14300\n",
            "[Train] Step: 341, w: 1.89508, b: 1.03658, loss: 0.14290\n",
            "[Train] Step: 342, w: 1.89643, b: 1.03658, loss: 0.14280\n",
            "[Train] Step: 343, w: 1.89777, b: 1.03659, loss: 0.14270\n",
            "[Train] Step: 344, w: 1.89910, b: 1.03659, loss: 0.14260\n",
            "[Train] Step: 345, w: 1.90041, b: 1.03659, loss: 0.14250\n",
            "[Train] Step: 346, w: 1.90171, b: 1.03659, loss: 0.14241\n",
            "[Train] Step: 347, w: 1.90299, b: 1.03659, loss: 0.14231\n",
            "[Train] Step: 348, w: 1.90426, b: 1.03660, loss: 0.14222\n",
            "[Train] Step: 349, w: 1.90552, b: 1.03660, loss: 0.14214\n",
            "[Train] Step: 350, w: 1.90677, b: 1.03660, loss: 0.14205\n",
            "[Train] Step: 351, w: 1.90800, b: 1.03660, loss: 0.14197\n",
            "[Train] Step: 352, w: 1.90922, b: 1.03660, loss: 0.14188\n",
            "[Train] Step: 353, w: 1.91042, b: 1.03660, loss: 0.14180\n",
            "[Train] Step: 354, w: 1.91161, b: 1.03661, loss: 0.14173\n",
            "[Train] Step: 355, w: 1.91279, b: 1.03661, loss: 0.14165\n",
            "[Train] Step: 356, w: 1.91396, b: 1.03661, loss: 0.14157\n",
            "[Train] Step: 357, w: 1.91512, b: 1.03661, loss: 0.14150\n",
            "[Train] Step: 358, w: 1.91626, b: 1.03661, loss: 0.14143\n",
            "[Train] Step: 359, w: 1.91739, b: 1.03661, loss: 0.14136\n",
            "[Train] Step: 360, w: 1.91851, b: 1.03661, loss: 0.14129\n",
            "[Train] Step: 361, w: 1.91961, b: 1.03661, loss: 0.14123\n",
            "[Train] Step: 362, w: 1.92070, b: 1.03661, loss: 0.14116\n",
            "[Train] Step: 363, w: 1.92179, b: 1.03661, loss: 0.14110\n",
            "[Train] Step: 364, w: 1.92286, b: 1.03661, loss: 0.14104\n",
            "[Train] Step: 365, w: 1.92391, b: 1.03661, loss: 0.14098\n",
            "[Train] Step: 366, w: 1.92496, b: 1.03661, loss: 0.14092\n",
            "[Train] Step: 367, w: 1.92599, b: 1.03661, loss: 0.14086\n",
            "[Train] Step: 368, w: 1.92702, b: 1.03662, loss: 0.14080\n",
            "[Train] Step: 369, w: 1.92803, b: 1.03662, loss: 0.14075\n",
            "[Train] Step: 370, w: 1.92903, b: 1.03662, loss: 0.14070\n",
            "[Train] Step: 371, w: 1.93002, b: 1.03662, loss: 0.14064\n",
            "[Train] Step: 372, w: 1.93100, b: 1.03662, loss: 0.14059\n",
            "[Train] Step: 373, w: 1.93197, b: 1.03662, loss: 0.14054\n",
            "[Train] Step: 374, w: 1.93292, b: 1.03662, loss: 0.14049\n",
            "[Train] Step: 375, w: 1.93387, b: 1.03662, loss: 0.14045\n",
            "[Train] Step: 376, w: 1.93481, b: 1.03662, loss: 0.14040\n",
            "[Train] Step: 377, w: 1.93573, b: 1.03662, loss: 0.14035\n",
            "[Train] Step: 378, w: 1.93664, b: 1.03662, loss: 0.14031\n",
            "[Train] Step: 379, w: 1.93755, b: 1.03662, loss: 0.14027\n",
            "[Train] Step: 380, w: 1.93844, b: 1.03662, loss: 0.14023\n",
            "[Train] Step: 381, w: 1.93933, b: 1.03662, loss: 0.14018\n",
            "[Train] Step: 382, w: 1.94020, b: 1.03662, loss: 0.14015\n",
            "[Train] Step: 383, w: 1.94106, b: 1.03662, loss: 0.14011\n",
            "[Train] Step: 384, w: 1.94192, b: 1.03662, loss: 0.14007\n",
            "[Train] Step: 385, w: 1.94276, b: 1.03662, loss: 0.14003\n",
            "[Train] Step: 386, w: 1.94359, b: 1.03662, loss: 0.14000\n",
            "[Train] Step: 387, w: 1.94442, b: 1.03662, loss: 0.13996\n",
            "[Train] Step: 388, w: 1.94523, b: 1.03662, loss: 0.13993\n",
            "[Train] Step: 389, w: 1.94604, b: 1.03662, loss: 0.13989\n",
            "[Train] Step: 390, w: 1.94683, b: 1.03662, loss: 0.13986\n",
            "[Train] Step: 391, w: 1.94762, b: 1.03662, loss: 0.13983\n",
            "[Train] Step: 392, w: 1.94840, b: 1.03662, loss: 0.13980\n",
            "[Train] Step: 393, w: 1.94917, b: 1.03662, loss: 0.13977\n",
            "[Train] Step: 394, w: 1.94993, b: 1.03662, loss: 0.13974\n",
            "[Train] Step: 395, w: 1.95068, b: 1.03662, loss: 0.13971\n",
            "[Train] Step: 396, w: 1.95142, b: 1.03662, loss: 0.13968\n",
            "[Train] Step: 397, w: 1.95215, b: 1.03662, loss: 0.13965\n",
            "[Train] Step: 398, w: 1.95287, b: 1.03662, loss: 0.13963\n",
            "[Train] Step: 399, w: 1.95359, b: 1.03662, loss: 0.13960\n",
            "[Train] Step: 400, w: 1.95430, b: 1.03662, loss: 0.13957\n",
            "[Train] Step: 401, w: 1.95500, b: 1.03662, loss: 0.13955\n",
            "[Train] Step: 402, w: 1.95569, b: 1.03662, loss: 0.13953\n",
            "[Train] Step: 403, w: 1.95637, b: 1.03662, loss: 0.13950\n",
            "[Train] Step: 404, w: 1.95704, b: 1.03662, loss: 0.13948\n",
            "[Train] Step: 405, w: 1.95771, b: 1.03662, loss: 0.13946\n",
            "[Train] Step: 406, w: 1.95836, b: 1.03662, loss: 0.13944\n",
            "[Train] Step: 407, w: 1.95901, b: 1.03662, loss: 0.13941\n",
            "[Train] Step: 408, w: 1.95966, b: 1.03662, loss: 0.13939\n",
            "[Train] Step: 409, w: 1.96029, b: 1.03662, loss: 0.13937\n",
            "[Train] Step: 410, w: 1.96092, b: 1.03662, loss: 0.13935\n",
            "[Train] Step: 411, w: 1.96153, b: 1.03662, loss: 0.13933\n",
            "[Train] Step: 412, w: 1.96215, b: 1.03662, loss: 0.13932\n",
            "[Train] Step: 413, w: 1.96275, b: 1.03662, loss: 0.13930\n",
            "[Train] Step: 414, w: 1.96334, b: 1.03662, loss: 0.13928\n",
            "[Train] Step: 415, w: 1.96393, b: 1.03662, loss: 0.13926\n",
            "[Train] Step: 416, w: 1.96451, b: 1.03662, loss: 0.13925\n",
            "[Train] Step: 417, w: 1.96509, b: 1.03662, loss: 0.13923\n",
            "[Train] Step: 418, w: 1.96566, b: 1.03662, loss: 0.13921\n",
            "[Train] Step: 419, w: 1.96622, b: 1.03662, loss: 0.13920\n",
            "[Train] Step: 420, w: 1.96677, b: 1.03662, loss: 0.13918\n",
            "[Train] Step: 421, w: 1.96732, b: 1.03662, loss: 0.13917\n",
            "[Train] Step: 422, w: 1.96786, b: 1.03662, loss: 0.13916\n",
            "[Train] Step: 423, w: 1.96839, b: 1.03662, loss: 0.13914\n",
            "[Train] Step: 424, w: 1.96891, b: 1.03662, loss: 0.13913\n",
            "[Train] Step: 425, w: 1.96943, b: 1.03662, loss: 0.13912\n",
            "[Train] Step: 426, w: 1.96995, b: 1.03662, loss: 0.13910\n",
            "[Train] Step: 427, w: 1.97045, b: 1.03662, loss: 0.13909\n",
            "[Train] Step: 428, w: 1.97095, b: 1.03662, loss: 0.13908\n",
            "[Train] Step: 429, w: 1.97145, b: 1.03662, loss: 0.13907\n",
            "[Train] Step: 430, w: 1.97193, b: 1.03662, loss: 0.13905\n",
            "[Train] Step: 431, w: 1.97241, b: 1.03662, loss: 0.13904\n",
            "[Train] Step: 432, w: 1.97289, b: 1.03662, loss: 0.13903\n",
            "[Train] Step: 433, w: 1.97336, b: 1.03662, loss: 0.13902\n",
            "[Train] Step: 434, w: 1.97382, b: 1.03662, loss: 0.13901\n",
            "[Train] Step: 435, w: 1.97428, b: 1.03662, loss: 0.13900\n",
            "[Train] Step: 436, w: 1.97473, b: 1.03662, loss: 0.13899\n",
            "[Train] Step: 437, w: 1.97517, b: 1.03662, loss: 0.13898\n",
            "[Train] Step: 438, w: 1.97561, b: 1.03662, loss: 0.13897\n",
            "[Train] Step: 439, w: 1.97605, b: 1.03662, loss: 0.13896\n",
            "[Train] Step: 440, w: 1.97648, b: 1.03662, loss: 0.13896\n",
            "[Train] Step: 441, w: 1.97690, b: 1.03662, loss: 0.13895\n",
            "[Train] Step: 442, w: 1.97732, b: 1.03662, loss: 0.13894\n",
            "[Train] Step: 443, w: 1.97773, b: 1.03662, loss: 0.13893\n",
            "[Train] Step: 444, w: 1.97813, b: 1.03662, loss: 0.13892\n",
            "[Train] Step: 445, w: 1.97853, b: 1.03662, loss: 0.13892\n",
            "[Train] Step: 446, w: 1.97893, b: 1.03662, loss: 0.13891\n",
            "[Train] Step: 447, w: 1.97932, b: 1.03662, loss: 0.13890\n",
            "[Train] Step: 448, w: 1.97971, b: 1.03662, loss: 0.13889\n",
            "[Train] Step: 449, w: 1.98009, b: 1.03662, loss: 0.13889\n",
            "[Train] Step: 450, w: 1.98046, b: 1.03662, loss: 0.13888\n",
            "[Train] Step: 451, w: 1.98083, b: 1.03662, loss: 0.13887\n",
            "[Train] Step: 452, w: 1.98120, b: 1.03662, loss: 0.13887\n",
            "[Train] Step: 453, w: 1.98156, b: 1.03662, loss: 0.13886\n",
            "[Train] Step: 454, w: 1.98191, b: 1.03662, loss: 0.13886\n",
            "[Train] Step: 455, w: 1.98226, b: 1.03662, loss: 0.13885\n",
            "[Train] Step: 456, w: 1.98261, b: 1.03662, loss: 0.13885\n",
            "[Train] Step: 457, w: 1.98295, b: 1.03662, loss: 0.13884\n",
            "[Train] Step: 458, w: 1.98329, b: 1.03662, loss: 0.13884\n",
            "[Train] Step: 459, w: 1.98362, b: 1.03662, loss: 0.13883\n",
            "[Train] Step: 460, w: 1.98395, b: 1.03662, loss: 0.13883\n",
            "[Train] Step: 461, w: 1.98427, b: 1.03662, loss: 0.13882\n",
            "[Train] Step: 462, w: 1.98459, b: 1.03662, loss: 0.13882\n",
            "[Train] Step: 463, w: 1.98490, b: 1.03662, loss: 0.13881\n",
            "[Train] Step: 464, w: 1.98521, b: 1.03662, loss: 0.13881\n",
            "[Train] Step: 465, w: 1.98552, b: 1.03662, loss: 0.13880\n",
            "[Train] Step: 466, w: 1.98582, b: 1.03662, loss: 0.13880\n",
            "[Train] Step: 467, w: 1.98612, b: 1.03662, loss: 0.13879\n",
            "[Train] Step: 468, w: 1.98641, b: 1.03662, loss: 0.13879\n",
            "[Train] Step: 469, w: 1.98670, b: 1.03662, loss: 0.13879\n",
            "[Train] Step: 470, w: 1.98699, b: 1.03662, loss: 0.13878\n",
            "[Train] Step: 471, w: 1.98727, b: 1.03662, loss: 0.13878\n",
            "[Train] Step: 472, w: 1.98755, b: 1.03662, loss: 0.13878\n",
            "[Train] Step: 473, w: 1.98782, b: 1.03662, loss: 0.13877\n",
            "[Train] Step: 474, w: 1.98809, b: 1.03662, loss: 0.13877\n",
            "[Train] Step: 475, w: 1.98836, b: 1.03662, loss: 0.13877\n",
            "[Train] Step: 476, w: 1.98862, b: 1.03662, loss: 0.13876\n",
            "[Train] Step: 477, w: 1.98888, b: 1.03662, loss: 0.13876\n",
            "[Train] Step: 478, w: 1.98914, b: 1.03662, loss: 0.13876\n",
            "[Train] Step: 479, w: 1.98939, b: 1.03662, loss: 0.13875\n",
            "[Train] Step: 480, w: 1.98964, b: 1.03662, loss: 0.13875\n",
            "[Train] Step: 481, w: 1.98988, b: 1.03662, loss: 0.13875\n",
            "[Train] Step: 482, w: 1.99012, b: 1.03662, loss: 0.13875\n",
            "[Train] Step: 483, w: 1.99036, b: 1.03662, loss: 0.13874\n",
            "[Train] Step: 484, w: 1.99060, b: 1.03662, loss: 0.13874\n",
            "[Train] Step: 485, w: 1.99083, b: 1.03662, loss: 0.13874\n",
            "[Train] Step: 486, w: 1.99106, b: 1.03662, loss: 0.13874\n",
            "[Train] Step: 487, w: 1.99128, b: 1.03662, loss: 0.13873\n",
            "[Train] Step: 488, w: 1.99150, b: 1.03662, loss: 0.13873\n",
            "[Train] Step: 489, w: 1.99172, b: 1.03662, loss: 0.13873\n",
            "[Train] Step: 490, w: 1.99194, b: 1.03662, loss: 0.13873\n",
            "[Train] Step: 491, w: 1.99215, b: 1.03662, loss: 0.13873\n",
            "[Train] Step: 492, w: 1.99236, b: 1.03662, loss: 0.13872\n",
            "[Train] Step: 493, w: 1.99256, b: 1.03662, loss: 0.13872\n",
            "[Train] Step: 494, w: 1.99277, b: 1.03662, loss: 0.13872\n",
            "[Train] Step: 495, w: 1.99297, b: 1.03662, loss: 0.13872\n",
            "[Train] Step: 496, w: 1.99316, b: 1.03662, loss: 0.13872\n",
            "[Train] Step: 497, w: 1.99336, b: 1.03662, loss: 0.13872\n",
            "[Train] Step: 498, w: 1.99355, b: 1.03662, loss: 0.13871\n",
            "[Train] Step: 499, w: 1.99374, b: 1.03662, loss: 0.13871\n",
            "[Train] Step: 500, w: 1.99392, b: 1.03662, loss: 0.13871\n",
            "[Train] Step: 501, w: 1.99411, b: 1.03662, loss: 0.13871\n",
            "[Train] Step: 502, w: 1.99429, b: 1.03662, loss: 0.13871\n",
            "[Train] Step: 503, w: 1.99447, b: 1.03662, loss: 0.13871\n",
            "[Train] Step: 504, w: 1.99464, b: 1.03662, loss: 0.13871\n",
            "[Train] Step: 505, w: 1.99482, b: 1.03662, loss: 0.13870\n",
            "[Train] Step: 506, w: 1.99499, b: 1.03662, loss: 0.13870\n",
            "[Train] Step: 507, w: 1.99515, b: 1.03662, loss: 0.13870\n",
            "[Train] Step: 508, w: 1.99532, b: 1.03662, loss: 0.13870\n",
            "[Train] Step: 509, w: 1.99548, b: 1.03662, loss: 0.13870\n",
            "[Train] Step: 510, w: 1.99564, b: 1.03662, loss: 0.13870\n",
            "[Train] Step: 511, w: 1.99580, b: 1.03662, loss: 0.13870\n",
            "[Train] Step: 512, w: 1.99596, b: 1.03662, loss: 0.13870\n",
            "[Train] Step: 513, w: 1.99611, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 514, w: 1.99626, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 515, w: 1.99641, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 516, w: 1.99656, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 517, w: 1.99670, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 518, w: 1.99684, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 519, w: 1.99698, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 520, w: 1.99712, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 521, w: 1.99726, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 522, w: 1.99739, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 523, w: 1.99752, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 524, w: 1.99765, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 525, w: 1.99778, b: 1.03662, loss: 0.13869\n",
            "[Train] Step: 526, w: 1.99791, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 527, w: 1.99803, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 528, w: 1.99815, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 529, w: 1.99827, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 530, w: 1.99839, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 531, w: 1.99851, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 532, w: 1.99862, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 533, w: 1.99873, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 534, w: 1.99884, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 535, w: 1.99895, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 536, w: 1.99906, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 537, w: 1.99917, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 538, w: 1.99927, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 539, w: 1.99938, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 540, w: 1.99948, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 541, w: 1.99958, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 542, w: 1.99967, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 543, w: 1.99977, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 544, w: 1.99987, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 545, w: 1.99996, b: 1.03662, loss: 0.13868\n",
            "[Train] Step: 546, w: 2.00005, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 547, w: 2.00014, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 548, w: 2.00023, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 549, w: 2.00032, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 550, w: 2.00040, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 551, w: 2.00049, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 552, w: 2.00057, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 553, w: 2.00066, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 554, w: 2.00074, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 555, w: 2.00082, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 556, w: 2.00089, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 557, w: 2.00097, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 558, w: 2.00105, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 559, w: 2.00112, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 560, w: 2.00120, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 561, w: 2.00127, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 562, w: 2.00134, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 563, w: 2.00141, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 564, w: 2.00148, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 565, w: 2.00154, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 566, w: 2.00161, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 567, w: 2.00168, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 568, w: 2.00174, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 569, w: 2.00180, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 570, w: 2.00187, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 571, w: 2.00193, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 572, w: 2.00199, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 573, w: 2.00205, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 574, w: 2.00211, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 575, w: 2.00216, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 576, w: 2.00222, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 577, w: 2.00227, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 578, w: 2.00233, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 579, w: 2.00238, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 580, w: 2.00244, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 581, w: 2.00249, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 582, w: 2.00254, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 583, w: 2.00259, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 584, w: 2.00264, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 585, w: 2.00269, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 586, w: 2.00273, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 587, w: 2.00278, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 588, w: 2.00283, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 589, w: 2.00287, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 590, w: 2.00292, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 591, w: 2.00296, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 592, w: 2.00300, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 593, w: 2.00305, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 594, w: 2.00309, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 595, w: 2.00313, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 596, w: 2.00317, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 597, w: 2.00321, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 598, w: 2.00325, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 599, w: 2.00328, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 600, w: 2.00332, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 601, w: 2.00336, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 602, w: 2.00339, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 603, w: 2.00343, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 604, w: 2.00346, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 605, w: 2.00350, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 606, w: 2.00353, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 607, w: 2.00357, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 608, w: 2.00360, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 609, w: 2.00363, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 610, w: 2.00366, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 611, w: 2.00369, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 612, w: 2.00372, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 613, w: 2.00375, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 614, w: 2.00378, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 615, w: 2.00381, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 616, w: 2.00384, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 617, w: 2.00387, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 618, w: 2.00389, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 619, w: 2.00392, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 620, w: 2.00395, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 621, w: 2.00397, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 622, w: 2.00400, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 623, w: 2.00402, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 624, w: 2.00405, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 625, w: 2.00407, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 626, w: 2.00409, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 627, w: 2.00412, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 628, w: 2.00414, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 629, w: 2.00416, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 630, w: 2.00418, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 631, w: 2.00421, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 632, w: 2.00423, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 633, w: 2.00425, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 634, w: 2.00427, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 635, w: 2.00429, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 636, w: 2.00431, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 637, w: 2.00433, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 638, w: 2.00435, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 639, w: 2.00436, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 640, w: 2.00438, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 641, w: 2.00440, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 642, w: 2.00442, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 643, w: 2.00444, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 644, w: 2.00445, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 645, w: 2.00447, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 646, w: 2.00448, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 647, w: 2.00450, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 648, w: 2.00452, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 649, w: 2.00453, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 650, w: 2.00455, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 651, w: 2.00456, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 652, w: 2.00458, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 653, w: 2.00459, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 654, w: 2.00460, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 655, w: 2.00462, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 656, w: 2.00463, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 657, w: 2.00465, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 658, w: 2.00466, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 659, w: 2.00467, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 660, w: 2.00468, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 661, w: 2.00470, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 662, w: 2.00471, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 663, w: 2.00472, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 664, w: 2.00473, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 665, w: 2.00474, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 666, w: 2.00476, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 667, w: 2.00477, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 668, w: 2.00478, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 669, w: 2.00479, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 670, w: 2.00480, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 671, w: 2.00481, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 672, w: 2.00482, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 673, w: 2.00483, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 674, w: 2.00484, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 675, w: 2.00485, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 676, w: 2.00486, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 677, w: 2.00486, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 678, w: 2.00487, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 679, w: 2.00488, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 680, w: 2.00489, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 681, w: 2.00490, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 682, w: 2.00491, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 683, w: 2.00491, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 684, w: 2.00492, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 685, w: 2.00493, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 686, w: 2.00494, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 687, w: 2.00495, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 688, w: 2.00495, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 689, w: 2.00496, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 690, w: 2.00497, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 691, w: 2.00497, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 692, w: 2.00498, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 693, w: 2.00499, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 694, w: 2.00499, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 695, w: 2.00500, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 696, w: 2.00501, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 697, w: 2.00501, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 698, w: 2.00502, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 699, w: 2.00502, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 700, w: 2.00503, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 701, w: 2.00503, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 702, w: 2.00504, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 703, w: 2.00505, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 704, w: 2.00505, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 705, w: 2.00506, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 706, w: 2.00506, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 707, w: 2.00507, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 708, w: 2.00507, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 709, w: 2.00508, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 710, w: 2.00508, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 711, w: 2.00508, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 712, w: 2.00509, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 713, w: 2.00509, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 714, w: 2.00510, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 715, w: 2.00510, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 716, w: 2.00511, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 717, w: 2.00511, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 718, w: 2.00511, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 719, w: 2.00512, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 720, w: 2.00512, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 721, w: 2.00513, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 722, w: 2.00513, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 723, w: 2.00513, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 724, w: 2.00514, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 725, w: 2.00514, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 726, w: 2.00514, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 727, w: 2.00515, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 728, w: 2.00515, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 729, w: 2.00515, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 730, w: 2.00516, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 731, w: 2.00516, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 732, w: 2.00516, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 733, w: 2.00516, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 734, w: 2.00517, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 735, w: 2.00517, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 736, w: 2.00517, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 737, w: 2.00518, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 738, w: 2.00518, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 739, w: 2.00518, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 740, w: 2.00518, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 741, w: 2.00519, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 742, w: 2.00519, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 743, w: 2.00519, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 744, w: 2.00519, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 745, w: 2.00519, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 746, w: 2.00520, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 747, w: 2.00520, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 748, w: 2.00520, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 749, w: 2.00520, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 750, w: 2.00520, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 751, w: 2.00521, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 752, w: 2.00521, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 753, w: 2.00521, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 754, w: 2.00521, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 755, w: 2.00521, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 756, w: 2.00522, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 757, w: 2.00522, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 758, w: 2.00522, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 759, w: 2.00522, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 760, w: 2.00522, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 761, w: 2.00522, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 762, w: 2.00523, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 763, w: 2.00523, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 764, w: 2.00523, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 765, w: 2.00523, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 766, w: 2.00523, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 767, w: 2.00523, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 768, w: 2.00523, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 769, w: 2.00524, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 770, w: 2.00524, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 771, w: 2.00524, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 772, w: 2.00524, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 773, w: 2.00524, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 774, w: 2.00524, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 775, w: 2.00524, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 776, w: 2.00524, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 777, w: 2.00524, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 778, w: 2.00525, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 779, w: 2.00525, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 780, w: 2.00525, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 781, w: 2.00525, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 782, w: 2.00525, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 783, w: 2.00525, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 784, w: 2.00525, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 785, w: 2.00525, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 786, w: 2.00525, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 787, w: 2.00525, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 788, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 789, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 790, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 791, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 792, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 793, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 794, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 795, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 796, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 797, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 798, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 799, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 800, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 801, w: 2.00526, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 802, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 803, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 804, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 805, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 806, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 807, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 808, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 809, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 810, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 811, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 812, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 813, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 814, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 815, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 816, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 817, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 818, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 819, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 820, w: 2.00527, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 821, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 822, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 823, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 824, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 825, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 826, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 827, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 828, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 829, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 830, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 831, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 832, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 833, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 834, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 835, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 836, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 837, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 838, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 839, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 840, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 841, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 842, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 843, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 844, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 845, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 846, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 847, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 848, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 849, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 850, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 851, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 852, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 853, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 854, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 855, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 856, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 857, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 858, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 859, w: 2.00528, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 860, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 861, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 862, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 863, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 864, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 865, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 866, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 867, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 868, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 869, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 870, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 871, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 872, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 873, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 874, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 875, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 876, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 877, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 878, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 879, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 880, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 881, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 882, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 883, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 884, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 885, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 886, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 887, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 888, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 889, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 890, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 891, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 892, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 893, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 894, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 895, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 896, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 897, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 898, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 899, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 900, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 901, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 902, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 903, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 904, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 905, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 906, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 907, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 908, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 909, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 910, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 911, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 912, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 913, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 914, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 915, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 916, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 917, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 918, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 919, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 920, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 921, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 922, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 923, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 924, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 925, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 926, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 927, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 928, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 929, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 930, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 931, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 932, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 933, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 934, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 935, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 936, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 937, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 938, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 939, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 940, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 941, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 942, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 943, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 944, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 945, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 946, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 947, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 948, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 949, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 950, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 951, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 952, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 953, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 954, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 955, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 956, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 957, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 958, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 959, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 960, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 961, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 962, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 963, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 964, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 965, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 966, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 967, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 968, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 969, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 970, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 971, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 972, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 973, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 974, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 975, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 976, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 977, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 978, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 979, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 980, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 981, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 982, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 983, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 984, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 985, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 986, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 987, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 988, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 989, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 990, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 991, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 992, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 993, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 994, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 995, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 996, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 997, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 998, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "[Train] Step: 999, w: 2.00529, b: 1.03662, loss: 0.13867\n",
            "预估值: 7.47359, 真实值: 7.42000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 构建模型\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(\"float\", name=\"x\")\n",
        "y = tf.placeholder(\"float\", name=\"y\")\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "def model(x, w, b):\n",
        "  return tf.multiply(x, w) + b\n",
        "\n",
        "w = tf.Variable(1.0, name='w0')\n",
        "b = tf.Variable(0.0, name='b0')\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "pred = model(x, w, b)\n",
        "\n",
        "loss_function = tf.reduce_mean(tf.square(y-pred))\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss_function)\n",
        "\n",
        "#训练\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(1000):\n",
        "  #单个样本输入\n",
        "  #for xs, ys in zip(x_data, y_data):\n",
        "  #  _, loss = sess.run([optimizer, loss_function], feed_dict={x: xs, y: ys})\n",
        "  #所有样本输入\n",
        "  _, loss = sess.run([optimizer, loss_function], feed_dict={x: x_data, y: y_data})\n",
        "\n",
        "b0temp=b.eval(session=sess)\n",
        "w0temp=w.eval(session=sess)\n",
        "print(\"Train finish, w: %4.5f, b: %4.5f\" % (w0temp, b0temp))\n",
        "\n",
        "#画出训练结果的曲线\n",
        "plt.plot(x_data, w0temp * x_data + b0temp)\n",
        "\n",
        "#画出我们想要学习到的线性函数 y = 2x + 1\n",
        "plt.plot(x_data, 2 * x_data + 1.0, color = 'red', linewidth = 3)\n",
        "\n",
        "y_p = sess.run(pred, feed_dict={x: [3.21]})\n",
        "print('预估值: %4.5f, 真实值: %4.5f' % (y_p[0], 3.21 * 2 +1))\n",
        "\n",
        "sess.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "bGGRlzBkM7jq",
        "outputId": "267fb02f-4c77-4cac-f639-8799d088aabc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"x:0\", dtype=float32)\n",
            "Tensor(\"y:0\", dtype=float32)\n",
            "<tf.Variable 'w0:0' shape=() dtype=float32_ref>\n",
            "<tf.Variable 'b0:0' shape=() dtype=float32_ref>\n",
            "Train finish, w: 2.00529, b: 1.03662\n",
            "预估值: 7.47359, 真实值: 7.42000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}